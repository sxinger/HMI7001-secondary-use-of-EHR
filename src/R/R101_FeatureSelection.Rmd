---
title: "Model Selection"
author: "Xing Song"
date: "11/08/2022"
output: html_document
---

Let's do some preparation for the class by running the following chunk of codes

```{r setup}
#set up rmd 
knitr::opts_chunk$set(message=F,
                      warning=F,
                      echo=F,
                      fig.width=12,
                      fig.height=10)

#load packages
pacman::p_load(tidyverse,pROC,leaps)

#load data
idd_bmi<-readRDS("./idd_bmi_final.rda")
```

**************************************************************************************************
**************************************************************************************************

Let's recall the logistic model we built last time to answer the research question:

> What are the risk factors for developing obstructive sleep apnea (OSA) among adult IDD patients? Can we build a predictive model for predicting likelihood of OSA among new IDD patients?

We built two logistic regression models, with different set of predictors: 

$$ Model 1: OSA\_ind = b0 + b1*bmi\_median $$

```{r}
fit1<-glm(OSA_ind ~ bmi_median, data=idd_bmi, family=binomial())
summary(fit1)
```

$$ Model 2: OSA\_ind = b0 + b1*bmi\_median + b2*age\_at\_firstdx$$

```{r}
fit2<-glm(OSA_ind ~ bmi_median+AGE_AT_FIRSTDX, data=idd_bmi, family=binomial())
summary(fit2)

anova(fit1,fit2,test="LRT")
```

What happens if we add `sex_f_ind` to the model, such that

$$ Model 3: OSA\_ind = b0 + b1*bmi\_median + b2*age + b3*sex\_f\_ind $$

```{r}
fit3<-glm(OSA_ind ~ bmi_median+AGE_AT_FIRSTDX+sex_f_ind, data=idd_bmi, family=binomial())
summary(fit3)

anova(fit2,fit3,test="LRT")
```

Should we keep `sex_f_ind` in the final model, then? Should we add other covariates (e.g. `race` or `diagnosis`) to the model in order to achieve better performance? There is a systemetic way to `scan` all relavent covariates independently or sequentially, to identify the set of covariates that are more likely to be associate with the outcome than the others. 


## Feature Selection

**Feature selection** refers to filtering of variables before building a predictive model. Algorithms may be able to handle “a lot” of variables, but selecting important ones is advantageous:
* Less likely to introduce “noise” by having irrelevant variables, and hence, less chance of overfitting
* Model building proceeds more quickly
* Models are easier to interpret


###  Methods for Feature Selection

* **Filter-based Method**: we first specify some measures of association (e.g. Pearson correlation, odds ratio, etc.), and then rank and filter features based on that measure. Ex: Univariate Analysis

* **Wrapper-based Method**: model-based methods that consider the selection of a set of features as a systematic search problem. Ex: Stepwise Regression Model

* **Embedded Method**: integrative algorithms with built-in feature selection mechanisms


### A Filter-based method – Univariate Analysis

* Step 1: Identify the measure of association between outcome and variable/feature of interest.

> recall that our outcome variable `OSA_ind` is binary, I will chose to use odds ratio as my filtering criteria


* Step 2: Calculate the measure for each one of the variable/feature and rank them from the highest to the lowest.

```{r}
var_to_be_filtered<-c("bmi_median",
                      "AGE_AT_FIRSTDX",
                      "sex_f_ind",
                      "DIAGNOSIS",
                      "RACE")

odds_ratio<-data.frame(variable=as.character(),
                       odds_ratio=as.numeric(),
                       p_value=as.numeric())

for (vari in var_to_be_filtered){
  cat("test variable:",vari,"\n")
  
  fit<-glm(as.formula(paste0("OSA_ind~",vari)),
           data=idd_bmi,
           family=binomial()
           )
  
  summ.fit<-summary(fit)
  
  odds_ratio<-odds_ratio %>%
    add_row(variable=vari,
            odds_ratio=exp(summ.fit$coefficients[2,1]), # note that the coefficient of logistic regression is the log-odds
            p_value=summ.fit$coefficients[2,4])
  
}

odds_ratio<-odds_ratio %>%
  arrange(p_value)
```


* Step 3: Determine number of variables included following certain rule. 

> using a cut-off point of p-value = 0.05, I will select the top three most significant variables (i.e. p < 0.05) to be included in the final model

```{r}
var_selected<-odds_ratio %>%
  filter(p_value<=0.05)

var_selected
```

```{r}
fit_filter<-glm(OSA_ind ~ DIAGNOSIS + bmi_median + AGE_AT_FIRSTDX, 
                data = idd_bmi, family = binomial())
summary(fit_filter)
```

Let's compare this model with one of the previous models, say fit2

```{r}
# compare their AUC
anova(fit3,fit_filter,test="LRT")
```


```{r}
# compare using ANOVA test for their residuals
fit2_roc<-pROC::roc(fit2$y, fit2$fitted)
fit_filter_roc<-pROC::roc(fit_filter$y, fit_filter$fitted)
pROC::ggroc(list(Model1=fit2_roc,
                 Model2=fit_filter_roc))+
  geom_abline(intercept=1,linetype=2)+
  labs(subtitle = paste0("AUC1:",round(fit2_roc$auc,4),"\n",
                         "AUC2:",round(fit_filter_roc$auc,4)))
```


### A Wrapper-based Method – Stepwise Regression

* Forward Regression

```{r}
# Specify a null model with no predictors
null_model <- glm(OSA_ind ~ 1, 
                  data = idd_bmi, family = binomial())

# Specify the full model using all of the potential predictors
full_model <- glm(OSA_ind ~ bmi_median+AGE_AT_FIRSTDX+sex_f_ind+DIAGNOSIS+RACE, 
                  data = idd_bmi, family = binomial())

# Use a forward stepwise algorithm to build a parsimonious model
step_model <- step(null_model,
                   scope = list(lower = null_model, upper = full_model),
                   direction = "forward")

# Estimate the stepwise predictted probability
fit_forward<-glm(OSA_ind ~ DIAGNOSIS + bmi_median + AGE_AT_FIRSTDX + sex_f_ind, 
                  data = idd_bmi, family = binomial())

summary(fit_forward)
```

* Backward Regression (Recursive Feature Elimination)

```{r}
# Specify a null model with no predictors
null_model <- glm(OSA_ind ~ 1, 
                  data = idd_bmi, family = binomial())

# Specify the full model using all of the potential predictors
full_model <- glm(OSA_ind ~ bmi_median+AGE_AT_FIRSTDX+sex_f_ind+DIAGNOSIS+RACE, 
                  data = idd_bmi, family = binomial())

# Use a forward stepwise algorithm to build a parsimonious model
step_model <- step(full_model,
                   scope = list(lower = null_model, upper = full_model),
                   direction = "backward")

# Estimate the stepwise predictted probability
fit_backward<-glm(OSA_ind ~ DIAGNOSIS + bmi_median + AGE_AT_FIRSTDX + sex_f_ind, 
                  data = idd_bmi, family = binomial())
```


* Bi-directional Stepwise Regression

```{r}
# Specify a null model with no predictors
null_model <- glm(OSA_ind ~ 1, 
                  data = idd_bmi, family = binomial())

# Specify the full model using all of the potential predictors
full_model <- glm(OSA_ind ~ bmi_median+AGE_AT_FIRSTDX+sex_f_ind+DIAGNOSIS+RACE, 
                  data = idd_bmi, family = binomial())

# Use a forward stepwise algorithm to build a parsimonious model
step_model <- step(null_model,
                   scope = list(lower = null_model, upper = full_model),
                   direction = "both")

# Estimate the stepwise predictted probability
fit_both<-glm(OSA_ind ~ DIAGNOSIS + bmi_median + AGE_AT_FIRSTDX + sex_f_ind, 
                  data = idd_bmi, family = binomial())
```


Ultimately, all the three stepwise regression models are suggesting the following final model: 

$$ OSA\_ind = b0 + b1*DIAGNOSIS + b2*bmi\_median + b3*AGE\_AT\_FIRSTDX + b4*sex\_f\_ind $$ 

```{r}
summary(fit_both)
```

Let's compare this model with fit_filter: 


```{r}
# compare their AUC
anova(fit_filter,fit_both,test="LRT")
```


```{r}
# compare using ANOVA test for their residuals
fit_filter_roc<-pROC::roc(fit_filter$y, fit_filter$fitted)
fit_both_roc<-pROC::roc(fit_both$y, fit_both$fitted)
pROC::ggroc(list(Model1=fit_filter_roc,
                 Model2=fit_both_roc))+
  geom_abline(intercept=1,linetype=2)+
  labs(subtitle = paste0("AUC1:",round(fit_filter_roc$auc,4),"\n",
                         "AUC2:",round(fit_both_roc$auc,4)))
```

